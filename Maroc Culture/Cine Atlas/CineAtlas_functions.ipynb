{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper CineAtlas avec des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "from ast import literal_eval\n",
    "\n",
    "url = 'https://www.cineatlas.com/'\n",
    "\n",
    "html_data = requests.get(url).text\n",
    "movieData = re.findall(r'movieData = ({.*?}), movieDataByReleaseDate', html_data, flags=re.DOTALL)[0]\n",
    "movieData = re.sub(r'\\s*/\\*.*?\\*/\\s*', '', movieData)   # remove comments\n",
    "movieData = literal_eval(movieData) # in movieData you have now the information about the current movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formater le JSON pour plus de lisibilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jfile = json.dumps(movieData, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(jfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper les dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier JSON est défini date par date. Il faut d'abord isoler ces données pour les réutiliser avec les fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11\n",
      "2019-08-12\n",
      "2019-08-13\n"
     ]
    }
   ],
   "source": [
    "dates = [ ]\n",
    "for k in data:\n",
    "    dates.append(k)\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------    Fonctions   -------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liens :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_liens(date):\n",
    "    mLiens = []\n",
    "    for i in data.get(date):\n",
    "        print(i['url'])\n",
    "        mLiens.append(\"https://www.cineatlas.com/movie/\"+str(i['url']))\n",
    "    return mLiens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noms :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_noms(date):\n",
    "    mNoms = []\n",
    "    for i in data.get(date):\n",
    "        print(i['title'])\n",
    "        mNoms.append((i['title']))\n",
    "    return mNoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_images(date):\n",
    "    mImages = []\n",
    "    for i in data.get(date):\n",
    "        print(i['image-portrait'])\n",
    "        mImages.append((i['image-portrait']))\n",
    "    return mImages\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heures :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_heures(date):\n",
    "    mHeures = []\n",
    "    heures = []\n",
    "    \n",
    "    for i in data.get(date):\n",
    "        h = []\n",
    "        for j in i['times']:\n",
    "            print(j['time'])\n",
    "            h.append(j['time'])\n",
    "        print(\" *** *** BUMPER *** ***\")\n",
    "        heures.append(h)\n",
    "    \n",
    "    for i in heures:\n",
    "        s = \"\"\n",
    "        for j in i:\n",
    "            s =s+str(j)+\" \"\n",
    "        mHeures.append(s)     \n",
    "        \n",
    "    return mHeures    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mDescs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_descriptions(date):\n",
    "    start_time = time()\n",
    "    requests = 0\n",
    "    \n",
    "   \n",
    "    for i in liens[0:5]:\n",
    "        print(i)\n",
    "        response = get(i)\n",
    "    \n",
    "        timer = randint(8,15)\n",
    "        #pause de loop\n",
    "        print(timer)\n",
    "        sleep(timer)\n",
    "    \n",
    "        #renvoyer un warning pour les non 'status code : 200'\n",
    "        if response.status_code != 200:\n",
    "            warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "            \n",
    "        #parser en BS\n",
    "        page_html = BeautifulSoup(response.text,'html.parser')  \n",
    "    \n",
    "        events = page_html.find('div',class_='mobile-hide movie-details-container')\n",
    "    \n",
    "        if events is None:\n",
    "            descs.append(\"NO DESCRIPTION\")\n",
    "            continue\n",
    "    \n",
    "        event = events.find('div',class_='movie-details')   \n",
    "    \n",
    "        \n",
    "        #dans le trou du cul du code (aka 4eme <p> du <div> cible )\n",
    "        print(event.findAll('p',recursive=False)[3].text)\n",
    "    \n",
    "        mDescs.append(event.findAll('p',recursive=False)[3].text)\n",
    "    \n",
    "    print(\"** Done **\")  \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------- TESTER LE BORDEL ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-08-11', '2019-08-12', '2019-08-13']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-08-11'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast--furious--hobbs--shaw\n",
      "ST00000406-toy-story-4\n",
      "comme-des-btes-2\n",
      "uglydolls\n",
      "midsommar\n",
      "annabelle-la-maison-du-mal\n",
      "ST00000442-le-roi-lion\n",
      "le-coup-du-siecle--the-hustle\n",
      "spider-manfar-from-home\n"
     ]
    }
   ],
   "source": [
    "a = scrape_liens(dates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
